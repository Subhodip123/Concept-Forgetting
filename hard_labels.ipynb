{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, TensorDataset\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.autograd import Variable\n",
    "from scipy import ndimage\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "torch.set_printoptions(precision=3)\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:1'    \n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "np.random.seed(44)\n",
    "torch.manual_seed(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        resnet = models.resnet18()\n",
    "        # Change the first convolutional layer for MNIST\n",
    "        resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # Change the last fully connected layer for MNIST\n",
    "        resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "        self.resnet = resnet\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    \n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_labels(inputs, expected_distribution):\n",
    "  # number of samples, number of classes\n",
    "  assert inputs.ndim == 2\n",
    "  assert expected_distribution.ndim == 1\n",
    "  assert np.sum(expected_distribution) == 1.0\n",
    "  n = inputs.shape[0]\n",
    "  d = inputs.shape[1]\n",
    "  # A large constant\n",
    "  CONSTANT = 10000.0\n",
    "  # some hacks to get algorithm working without custom datasets.\n",
    "  augmented_inputs = np.zeros((n, d + 1), dtype=np.float32)\n",
    "  augmented_inputs[:, :-1] = inputs\n",
    "  augmented_inputs[:, -1] = -CONSTANT #augmented inputs with the last column denoting the lowest value for all samples shape=(n,d+1)\n",
    "  standard_inputs = np.zeros_like(augmented_inputs[0,:])\n",
    "  standard_inputs[-1] = CONSTANT #standard input with shape=(d+1,) with the last entry being the highest\n",
    "  expected_counts = n * expected_distribution #expected no of samples in each class\n",
    "  expected_counts = expected_counts.astype(np.int32)\n",
    "#   print(expected_counts)\n",
    "\n",
    "  ## loop to make the expected count sum=n\n",
    "  index = 0\n",
    "  while np.sum(expected_counts) < n:\n",
    "    expected_counts[index] += 1\n",
    "    index += 1\n",
    "    if index >= n:\n",
    "      index = 0\n",
    "#   print(expected_counts)\n",
    "\n",
    "  hard_samples_by_class = [0 for _ in range(d)]\n",
    "  sampled_ids = []\n",
    "  sample_to_hard_id = {}\n",
    "  while sum(hard_samples_by_class) < n:\n",
    "    nonsampled_ids = []\n",
    "    max_inputs = np.max(augmented_inputs, axis=-1) #max values across columns for each datapoint shape(n,)\n",
    "    max_inputs_class = np.argmax(augmented_inputs, axis=-1) #index of the max values across columns or class for each datapoint shape(n,) \n",
    "    sorted_sampels = np.flip(np.argsort(max_inputs)) #index of the highest to lowest among max values across datapoint/rows shape(n,)\n",
    "  \n",
    "    for i in range(n):\n",
    "      current_sample_id = sorted_sampels[i] #index of the highest to lowest sample based on max values\n",
    "      max_class = max_inputs_class[current_sample_id] #class of the current sample index  \n",
    "      if max_class == d: #did not understand this logic\n",
    "        continue\n",
    "      # print(max_class)\n",
    "      # print('done')\n",
    "      if hard_samples_by_class[max_class] < expected_counts[max_class]:\n",
    "        hard_samples_by_class[max_class] += 1\n",
    "        sample_to_hard_id[current_sample_id] = max_class\n",
    "        sampled_ids.append(current_sample_id)\n",
    "      else:\n",
    "        nonsampled_ids.append(current_sample_id)\n",
    "      # print(sampled_ids)\n",
    "      # print(nonsampled_ids)\n",
    "      # print('hi')\n",
    "      for k in sampled_ids:\n",
    "        augmented_inputs[k, :] = standard_inputs\n",
    "      for k in nonsampled_ids:\n",
    "        augmented_inputs[k, max_inputs_class[k]] = -CONSTANT\n",
    "  samples = np.ones(n, dtype=np.int32)\n",
    "  for sample in sample_to_hard_id.keys():\n",
    "    samples[sample] = sample_to_hard_id[sample]\n",
    "  return samples\n",
    "\n",
    "\n",
    "\n",
    "def max_pred_distribution(model, test_loader, display=True):\n",
    "    \"\"\"Predictive distribution using deterministic max\"\"\"\n",
    "    model.eval()\n",
    "    predictions= []\n",
    "    targets = []\n",
    "    pred_dist = []\n",
    "\n",
    "    with torch.no_grad():  \n",
    "      for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        # target = target.to(device)\n",
    "        output = model(data)\n",
    "        output_prob = F.softmax(output, dim=1).to(device='cpu')\n",
    "        pred_dist.append(output_prob.numpy())\n",
    "        pred = output.data.max(1, keepdim=True)[1].to('cpu').numpy()\n",
    "        # print(pred)\n",
    "        predictions.append(pred)\n",
    "        targets.append(target)\n",
    "        data.detach().cpu()\n",
    "        target.detach().cpu()\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    # print(predictions.shape)\n",
    "    predictions = predictions.reshape((predictions.shape[0],))\n",
    "    # print(predictions)\n",
    "    targets = torch.cat(targets, dim=0).to(device='cpu')\n",
    "    # print(targets)\n",
    "    \n",
    "    if display:\n",
    "        cm = confusion_matrix(targets, predictions, labels=[0,1,2,3,4,5,6,7,8,9], normalize='true')\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ConfusionMatrixDisplay(cm).plot(ax=ax)\n",
    "    \n",
    "    return cm,predictions\n",
    "\n",
    "\n",
    "\n",
    "## Test and training functions\n",
    "def test(model, loader, criterion, dname=\"Test set\", printable=True):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in loader:\n",
    "      data = data.to(device)\n",
    "      target = target.to(device)\n",
    "      output = model(data)\n",
    "      total += target.size()[0]\n",
    "      test_loss += criterion(output, target).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      # target = target.data.max(1, keepdim=True)[1]\n",
    "      # print(pred.shape)\n",
    "      # print(target.shape)\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      data.detach().cpu()\n",
    "      target.detach().cpu()\n",
    "  # test_loss /= len(loader.dataset)\n",
    "  if printable:\n",
    "    print('{}: total test loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        dname, test_loss, correct, total, \n",
    "        100. * correct / total\n",
    "        ))\n",
    "  return correct / total, test_loss\n",
    "\n",
    "\n",
    "def unlearn_train_hard_labels(model, epoch, thr_train_loader, nthr_train_loader, thr_test_loader, nthr_test_loader,\n",
    "                  criterion, hard_labels, expected_distribution, optimizer, alpha=1, gamma=1, ref_class=3, num_classes=10):\n",
    "  \n",
    "  #change the labels of class-3 to other hard labels\n",
    "  model.eval()\n",
    "  ref_output_probs = []\n",
    "  ref_hard_targets = []\n",
    "  # print(len(thr_train_loader.dataset))\n",
    "  # print(len(thr_train_loader)*(thr_train_loader.batch_size))\n",
    "  for ref_data,_ in thr_train_loader:\n",
    "    ref_data = ref_data.to(device)\n",
    "    ref_output = model(ref_data)\n",
    "    ref_output_prob = F.softmax(ref_output, dim=1).detach().to('cpu').numpy()\n",
    "    # print('a',ref_output_prob.shape)\n",
    "    # ref_target_hard = hard_labels(ref_output_prob, expected_distribution)\n",
    "    # ref_hard_targets.append(ref_target_hard)\n",
    "    ref_output_probs.append(ref_output_prob)\n",
    "  \n",
    "  ref_output_probs = np.concatenate(ref_output_probs, axis=0)\n",
    "  ref_hard_targets = hard_labels(ref_output_probs, expected_distribution)\n",
    "  # ref_hard_targets = np.concatenate(ref_hard_targets, axis=0)\n",
    "  # print('b',ref_hard_targets.shape)\n",
    "  print(Counter(ref_hard_targets))\n",
    "  ref_hard_targets_loader = DataLoader(torch.tensor(ref_hard_targets), batch_size=64)\n",
    "  \n",
    "  #unlearning loop\n",
    "  model.train()\n",
    "  unlearn_train_loss = 0\n",
    "  N = 0\n",
    "  for ((nonref_data, nonref_target),(ref_data, _ ), hard_targets_batch) in zip(nthr_train_loader, thr_train_loader, ref_hard_targets_loader):\n",
    "    \n",
    "    #non-ref data and targets\n",
    "    nonref_data = nonref_data.to(device)\n",
    "    nonref_target = nonref_target.to(device)\n",
    "    \n",
    "    #ref data and soft targets\n",
    "    ref_data = ref_data.to(device)\n",
    "    hard_targets_batch = hard_targets_batch.type(torch.LongTensor)\n",
    "    hard_targets_batch = hard_targets_batch.to('cuda:1')\n",
    "    optimizer.zero_grad()\n",
    "    nonref_output = model(nonref_data)\n",
    "    ref_output = model(ref_data)\n",
    "    nonref_loss = criterion(nonref_output, nonref_target)\n",
    "    ref_loss = criterion(ref_output,hard_targets_batch)\n",
    "    loss = alpha * nonref_loss + gamma * ref_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    unlearn_train_loss += loss.item()\n",
    "    N += len(nonref_data)\n",
    "    nonref_data.detach().cpu()\n",
    "    nonref_target.detach().cpu()\n",
    "    ref_data.detach().cpu()\n",
    "    # ref_hard_targets.detach().cpu()\n",
    "\n",
    "  # avg_train_loss = train_loss/N\n",
    "  print(\"Epoch: {} \\ total train Loss: {:.6f}\".format(\n",
    "        epoch, unlearn_train_loss\n",
    "    ))\n",
    "  \n",
    "  thr_test_acc, thr_test_loss = test(model, thr_test_loader, criterion=criterion, dname=\"Threes Test data\", printable=True)\n",
    "  nthr_test_acc, nthr_test_loss = test(model, nthr_test_loader, criterion=criterion, dname=\"Nonthree Test data\", printable=True)\n",
    "\n",
    "  return thr_test_acc, thr_test_loss, nthr_test_acc, nthr_test_loss, unlearn_train_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_neg_datasplit(class_number, dataset):\n",
    "    \"\"\"Test data splitting\"\"\"\n",
    "    # Test dataloader with 3's only\n",
    "    test_threes_index = []\n",
    "    test_nonthrees_index = []\n",
    "    for i in range(0, len(dataset)):\n",
    "      if dataset.targets[i] == class_number:\n",
    "        test_threes_index.append(i)\n",
    "      else:\n",
    "        test_nonthrees_index.append(i)\n",
    "    \n",
    "\n",
    "    three_test_loader = DataLoader(dataset, batch_size=64,\n",
    "                  sampler = SubsetRandomSampler(test_threes_index),drop_last=True)\n",
    "    nonthree_test_loader = DataLoader(dataset, batch_size=64,\n",
    "                  sampler = SubsetRandomSampler(test_nonthrees_index),drop_last=True)\n",
    "    \n",
    "    return three_test_loader, nonthree_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,),(0.5,)),\n",
    "                                ])\n",
    "\n",
    "# Using MNIST\n",
    "traindata = datasets.MNIST('/home/ece/Subhodip/data', download=False, train=True, transform=transform)\n",
    "testdata = datasets.MNIST('/home/ece/Subhodip/data', download=False, train=False, transform=transform)\n",
    "\n",
    "\n",
    "# Loaders that give 64 example batches\n",
    "all_data_train_loader = torch.utils.data.DataLoader(traindata, batch_size=64, shuffle=True)\n",
    "all_data_test_loader = torch.utils.data.DataLoader(testdata, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "#pos and neg data splitting for train and test dataset\n",
    "neg_test_loader, pos_test_loader = pos_neg_datasplit(class_number=3, dataset=testdata)\n",
    "neg_train_loader, pos_train_loader = pos_neg_datasplit(class_number=3, dataset=traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forgetting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[0.0001,0.0005,0.001,0.005,0.01,0.04,0.16,0.64]\n",
    "gammas=[0.25,0.5,1,2,4]\n",
    "expected_dist_list = [1,1,1,0,1,1,1,1,1,1]\n",
    "expected_pred_dist = np.array(expected_dist_list) * 1/9\n",
    "neg_ind=3\n",
    "gamma_list = []\n",
    "lr_list = []\n",
    "non_three_accuracies_list = []\n",
    "l1_distance_list = []\n",
    "for gamma in gammas:\n",
    "    for lr in learning_rates:\n",
    "        print(f\"learning_rate:{lr} and gamma:{gamma}\")\n",
    "        forget_resnet = CustomResNet18(in_channels=1, num_classes=10).to(device)\n",
    "        forget_optimizer = optim.Adam(forget_resnet.parameters(), lr=lr)\n",
    "        path = F\"../checkpoints/resnet/pretrained/trained.pt\"\n",
    "        checkpoint = torch.load(path)\n",
    "        forget_resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # forget_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        criterion = CrossEntropyLoss(reduction='mean')\n",
    "        forgetfulepochs = 1\n",
    "\n",
    "\n",
    "        unlearning_losses = {'total_unlearning_losses':[], 'thr_test_losses':[], 'nthr_test_losses':[]}\n",
    "        unlearning_acces = {'thr_test_accs': [], 'nthr_test_accs': []}\n",
    "        # Train model for forgetting\n",
    "        for epoch in range(0,forgetfulepochs+1):\n",
    "            if epoch == 0:\n",
    "                thr_test_acc, thr_test_loss = test(forget_resnet, neg_test_loader,criterion=criterion, dname=\"Threes Test Data\", printable=False)\n",
    "                nthr_test_acc, nthr_test_loss = test(forget_resnet, pos_test_loader, criterion=criterion, dname=\"Nonthrees Test Data\", printable=False)\n",
    "                unlearning_loss = 1000\n",
    "            else:\n",
    "                \n",
    "                thr_test_acc, thr_test_loss, nthr_test_acc, nthr_test_loss, unlearning_loss = unlearn_train_hard_labels(model=forget_resnet, epoch=epoch, \n",
    "                                                                            thr_train_loader=neg_train_loader,\n",
    "                                                                            nthr_train_loader=pos_train_loader, \n",
    "                                                                            thr_test_loader=neg_test_loader,\n",
    "                                                                            nthr_test_loader=pos_test_loader,criterion=criterion, \n",
    "                                                                            hard_labels = get_hard_labels, expected_distribution=expected_pred_dist,\n",
    "                                                                            optimizer=forget_optimizer, gamma=gamma, ref_class=3, num_classes=10)\n",
    "\n",
    "            unlearning_losses['total_unlearning_losses'].append(unlearning_loss)\n",
    "            unlearning_losses['thr_test_losses'].append(thr_test_loss)\n",
    "            unlearning_losses['nthr_test_losses'].append(nthr_test_loss)\n",
    "            \n",
    "            unlearning_acces['thr_test_accs'].append(thr_test_acc.to('cpu').item())\n",
    "            unlearning_acces['nthr_test_accs'].append(nthr_test_acc.to('cpu').item())\n",
    "            #for max_pred\n",
    "\n",
    "        #accuracy on pos classes\n",
    "        cm,_= max_pred_distribution(forget_resnet,test_loader=pos_test_loader)\n",
    "        accuracies = [cm[i, i] for i in range(min(cm.shape))]\n",
    "        print(\"Hard Labels\")\n",
    "        del accuracies[neg_ind]\n",
    "\n",
    "        print(\"Non Three Accuracies:\",np.mean(accuracies))\n",
    "        target_label = neg_ind  # Replace with the label you are interested in\n",
    "\n",
    "    # Get the column corresponding to the specified label\n",
    "        # print(cm)\n",
    "        cm2,_= max_pred_distribution(forget_resnet,test_loader=neg_test_loader)\n",
    "\n",
    "        column_for_label = cm2[target_label]\n",
    "        # print(column_for_label)\n",
    "        l1_distance = np.sum(np.abs(column_for_label - expected_pred_dist))\n",
    "\n",
    "        print(\"l1_distance\",l1_distance)\n",
    "        gamma_list.append(gamma)\n",
    "        lr_list.append(lr)\n",
    "        non_three_accuracies_list.append(np.mean(accuracies))\n",
    "        l1_distance_list.append(l1_distance)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # if epoch % 10 == 0:\n",
    "        #     print('saving at epoch=',epoch)\n",
    "        #     path = f\"../checkpoints/resnet/label-smooth/gamma_{gamma}/labelsmooth-{epoch}-{lr}.pt\"\n",
    "        #     torch.save({ \n",
    "        #             'model_state_dict': forget_resnet.state_dict(),\n",
    "        #             'optimizer_state_dict': forget_optimizer.state_dict(),\n",
    "        #             }, path)\n",
    "            \n",
    "        # loss_history = pd.DataFrame(unlearning_losses)\n",
    "        # loss_history.plot(figsize=(8,5))\n",
    "        # acc_history = pd.DataFrame(unlearning_acces)\n",
    "        # acc_history.plot(figsize=(8,5))\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Gamma': gamma_list,\n",
    "    'Learning Rate': lr_list,\n",
    "    'Non Three Accuracies': non_three_accuracies_list,\n",
    "    'L1 Distance': l1_distance_list\n",
    "})\n",
    "csv_filename = \"./results/hard_labels_forgetting_epoch1.csv\"\n",
    "results_df.to_csv(csv_filename, index=False)    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
